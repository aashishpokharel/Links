from alignment_model.model import DVQAModel
from alignment_model.inference import alignment_model_inference, correct_orientation
from ocr.extract_text_custom_ocr import extract_text_and_update_json



aligned_images = self.get_aligned(self.images)
            for i, image in enumerate(aligned_images):


def get_aligned(self, images):
        start_time = time.time()
        corrected_images = [correct_orientation(self.orientation_model, self.device, np.array(img)) for img in images]
        print("Orientation model time", time.time() - start_time)
        start_time = time.time()
        # aligned_images = [alignment_model_inference(self.alignment_model, self.device,
        #                                           [img]) for img in corrected_images]
        aligned_images = alignment_model_inference(self.alignment_model, self.device,
                                                  corrected_images)
        print("Alignment model time", time.time() - start_time)
        
        encoded_images = []
        for aligned_image in aligned_images:
            image_pil = Image.fromarray(aligned_image)        
            image_bytes = io.BytesIO()
            image_pil.save(image_bytes, format='png')
            encoded_images.append(base64.b64encode(image_bytes.getvalue()))
        return encoded_images

# CONFIg 
  alignment_model_path: '/mnt/gime-extract/global_ime/extraction_engine_demo_ml/alignment_model/model/checkpoints/55.pth'
  pulc_model_path: '/mnt/gime-extract/global_ime/extraction_engine_demo_ml/alignment_model/model/checkpoints/pulc'
  pulc_class_id_map_file: '/mnt/gime-extract/global_ime/extraction_engine_demo_ml/alignment_model/model/checkpoints/text_image_orientation_label_list.txt'
  dit_model_path: ''
  detr_model_path: "/mnt/gime-extract/global_ime/detr/detr/TATR-v1.1-All-msft.pth"
  detr_model_device: "cpu"
  detr_config_file: "/mnt/gime-extract/global_ime/detr/detr/structure_config.json"
  # OCR
  custom_ocr_path: "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/ocr/custom_ocr/model/796_2.pth"
  custom_ocr_char_path: "./ocr/custom_ocr/combined_char.txt"
  custom_ocr_config_path: "./ocr/custom_ocr/config.json"
  custom_ocr_batch_size: 32

# INIT
self.alignment_model = DVQAModel().to(self.device)
        checkpoint = torch.load(config['alignment_model_path'], map_location=self.device)
        self.alignment_model.load_state_dict(checkpoint['model'])
        self.alignment_model.to(self.device)
        self.orientation_model = PaddleClas(
                               inference_model_dir=config['pulc_model_path'], 
                               use_gpu=False, 
                               class_id_map_file=config['pulc_class_id_map_file'],
                               resize_short=1120,
                               crop_size=1120,
                               )
        

