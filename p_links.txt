
import os
import logging
import time
import sys
import torch
import pdb 
from alignment_model.model import DVQAModel
from pathlib import Path
from paddleclas import PaddleClas
# sys.path.append("../Info-Extraction-Engine-ML/modified_code/extraction_engine_demo_ml")

import io
import re
import json 
import cv2 

from utils import save_crop_images
import fitz
import base64
import numpy as np
import pandas as pd
from pdf2image import convert_from_bytes, convert_from_path

from PIL import Image, ImageSequence

from alignment_model.inference import alignment_model_inference, correct_orientation
from app import get_dit_output
from html_creator.generate_html import generate_html
# from pdf2text.extract_text import process_pdf_and_update_json
from ocr.extract_text_custom_ocr import extract_text_and_update_json
# from ocr.extract_text_tesseract import process_pdf_and_update_json
from document_layout_understanding.postprocess import postprocess_dit
from table_structure_recognition.inference import table_extract, TableExtractionPipeline
from llm.llm_inference import LLM_INFERENCE
from llm.gpt_inference import run
from PIL import Image
from visualizer.visualize import visualize_dit
import yaml
import pandas as pd


# folder to load config file
CONFIG_PATH = "."

def load_config(config_name):
    with open(os.path.join(CONFIG_PATH, config_name)) as file:
        config = yaml.safe_load(file)

    return config


config = load_config("config.yaml")

upload_dir = config['upload_dir']
os.makedirs(upload_dir, exist_ok=True)



class MainInference:
    def __init__(self):
        self.pdf = config['pdf_path']
        self.keys = config['questions']
        self.images = None
        self.dit_api = config['dit_api']
        # self.llm_inference = LLM_INFERENCE()
        self.llm_inference = None
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        # print(device)
        self.alignment_model = DVQAModel().to(self.device)
        checkpoint = torch.load(config['alignment_model_path'], map_location=self.device)
        self.alignment_model.load_state_dict(checkpoint['model'])
        self.alignment_model.to(self.device)
        self.orientation_model = PaddleClas(
                               inference_model_dir=config['pulc_model_path'], 
                               use_gpu=False, 
                               class_id_map_file=config['pulc_class_id_map_file'],
                               resize_short=1120,
                               crop_size=1120,
                               )
        
        self.pipe = TableExtractionPipeline(
            str_config_path=config['detr_config_file'],
            str_model_path=config['detr_model_path'],
            str_device=config['detr_model_device'],
        )

    def inference(self, pdf, keys, llm= 'gpt',images=None, debug = False):
        """

        Args:
            pdf:
            keys:
            images:

        Returns:

        """
        debug = True
        # try:
        if True:
            self.pdf = pdf
            self.keys = keys
            self.images = images
            OUTPUT_DIR = os.path.join(upload_dir, str(time.time()))
            os.makedirs(OUTPUT_DIR, exist_ok=True)
                
            SAVE_DIR = "/mnt/gime-extract/global_ime/data/aashish_run_apr2"  
            OCR_SAVE_DIR = "/mnt/gime-extract/global_ime/data/aashish_run_apr2/ocr"  
            
            os.makedirs(SAVE_DIR, exist_ok=True)
            os.makedirs(OCR_SAVE_DIR, exist_ok= True)
        
            if Path(self.pdf).suffix == '.pdf':
                # self.images = convert_from_bytes(pdf_bytes)
                pdf_document = fitz.open(self.pdf)
                self.images = convert_from_path(self.pdf)
                # TODO update image saving logic: low priority for now
                for i, image in enumerate(self.images):
                    image_path = os.path.join(OUTPUT_DIR, f'page{i}.png')
                    # todo why is this image being saved
                    image.save(image_path)
            else:
                self.images = [Image.open(self.pdf)]
                pdf_document = None
                for i, image in enumerate(self.images):
                    image_path = os.path.join(OUTPUT_DIR, f'page{i}.png')
                    # todo why is this image being saved
                    image.save(image_path)    
                    
            results = []
            htmls   = []
            extracted_texts = []
            for i, image in enumerate(self.images):
                result = {}
                # result['page_number'] = i
                image_path = os.path.join(OUTPUT_DIR, f'page{i}.png')
                # todo why is this image being saved
                file = open(image_path, 'rb')
                # todo base64 encoding optional for now, use default bytes array
                base64_encoded_image = base64.b64encode(file.read())
                #  Get aligned image
                base64_encoded_image = self.get_aligned(base64_encoded_image, process_image= True)
                
                decode_data = base64.b64decode(base64_encoded_image) 
                image = Image.open(io.BytesIO(decode_data)) 
                if debug:
                    aligned_image_path = f"{SAVE_DIR}/aligned_image"
                    if not os.path.exists(aligned_image_path):
                        os.makedirs(aligned_image_path)
        
                    image.save(f"{aligned_image_path}/{pdf.split('/')[-1]}-page{i}.png") 
                
                dit_output = get_dit_output(self.dit_api, base64_encoded_image) 
                
                if debug:
                    dit_img_raw = visualize_dit(dit_output) 
                    dit_path_raw = f"{SAVE_DIR}/DIT/raw"
                    if not os.path.exists(dit_path_raw):
                        os.makedirs(dit_path_raw)
        
                    cv2.imwrite(f"{dit_path_raw}/{pdf.split('/')[-1]}-page{i}.png", dit_img_raw) 
                    
                dit_output = postprocess_dit(dit_output)
                # if "Table" not in dit_output['jsonData']['classes']:
                #     continue
                
                if debug:
                    dit_img = visualize_dit(dit_output) 
                    dit_path = f"{SAVE_DIR}/DIT"
                    if not os.path.exists(dit_path):
                        os.makedirs(dit_path)
        
                    cv2.imwrite(f"{dit_path}/{pdf.split('/')[-1]}-page{i}.png", dit_img) 
                
                tables_boxes = []
                tables_classes = []
                tables_scores = []
                for j, b_cls in enumerate(dit_output['jsonData']['classes']):
                    # Filtering The table values and other values
                    box_class = b_cls
                    if box_class == "Table":
                        tables_boxes.append(dit_output['jsonData']['boxes'][j])
                        tables_classes.append(dit_output['jsonData']['classes'][j])
                        tables_scores.append(dit_output['jsonData']['scores'][j])
                values_to_pass_to_tsr = {
                    'jsonData':
                        {
                            'boxes': tables_boxes,
                            'classes': tables_classes,
                            "scores": tables_scores,
                            'image': dit_output['jsonData']['image']
                        },
                    'page_number': i,
                    'pdf': pdf_document,
                }
                decoded = base64.b64decode(base64_encoded_image)
                aligned_image = Image.open(io.BytesIO(decoded)).convert("RGB")
                height, width = aligned_image.size

                text_extract = extract_text_and_update_json(aligned_image, dit_output)
                
                if debug:
                    
                    ocr_save_path = f"{OCR_SAVE_DIR}/{SAVE_DIR.split('/')[-1]}/{pdf.split('/')[-1].split('.')[0]}/page-{i}"
                    if not os.path.exists(ocr_save_path):
                        os.makedirs(ocr_save_path, exist_ok=True)
                    
                    bounding_boxes = dit_output.get('jsonData', {}).get('boxes', [])
                    classes = dit_output.get('jsonData', {}).get('classes', []) 
                    texts = dit_output['jsonData']["extracted_text"]
                    for idx, bbox in enumerate(bounding_boxes):
                        if classes[idx] in ["Table", "Picture"]:
                            continue
                        left, top, right, bottom = bbox   
                        image = aligned_image.crop((left,top,right,bottom))
                        image.save(f"{ocr_save_path}/{idx}.jpg")
                        extracted_texts.append({
                            "image": f"page-{i}/{idx}.jpg",
                            "page_no": i,
                            "text": texts[idx].replace("<p>", "").replace("</p>", "\n").strip()
                        })
                        
                        
                tables_htmls = table_extract(self.pipe, values_to_pass_to_tsr, page_no=i, filename=f"{pdf.split('/')[-1]}-page{i}", filepath=f'{SAVE_DIR}/tsr/', ocr_save_path=ocr_save_path, debug=debug)
                
                page_html = generate_html(text_extract, tables_htmls)
                htmls.append(page_html)   
                
                if debug:
                    print(text_extract['jsonData']["extracted_text"])
                    print(text_extract['jsonData']["extracted_text_confidence"])
                    html_path = f"{SAVE_DIR}/html"
                    if not os.path.exists(html_path):
                        os.makedirs(html_path)
                    filename = f"{pdf.split('/')[-1]}-page{i}"
                    with open(f"{os.path.join(html_path, filename)}.html", 'w') as htm:
                        htm.write(page_html)
                if llm =='regex':
                    from llm.regex import balance_sheet_extraction
                    assets, liabilities = balance_sheet_extraction(htmls=[page_html,])
                    if isinstance(assets, pd.DataFrame) and isinstance(liabilities, pd.DataFrame) : 
                        return assets, liabilities

                
                # print("---------------------------H-T-M-L-----------------------")
                # with open(f"/mnt/gime-extract/global_ime/data/jan19output/html/{pdf.split('/')[-1]}-{i}.html", 'w') as f:
                #     f.write(page_html)
            
            if debug:
                file_name = pdf.split('/')[-1].split(".")[0]
                df = pd.DataFrame.from_dict(extracted_texts)
                tables_df_list = [pd.read_csv(f"{OCR_SAVE_DIR}/{SAVE_DIR.split('/')[-1]}/{pdf.split('/')[-1].split('.')[0]}/page-{i}/table_ocr.csv") for i in range(len(self.images))]
                
                combined_df_list = [df] + tables_df_list
                combined_df = pd.concat(combined_df_list, ignore_index=True)
                combined_df.to_csv(os.path.join(OCR_SAVE_DIR, SAVE_DIR.split('/')[-1], pdf.split('/')[-1].split('.')[0], f"{file_name}.csv"), index=False)
            llm = "none"
            filtered_result = []
            
            if llm != 'regex':
                context = " ".join(htmls)
                if llm == 'gpt':
                    llm_result = run(prompt=page_html, questions= self.keys)
                    # print("LLM RESULT-------------------------------", llm_result)
                    updated_result = [dict(item, **{'page_number': i, 'html':page_html}) for item in llm_result]
                    filtered_result = updated_result
                elif llm=="mistral":
                    llm_result = self.llm_inference(question= self.keys, prompt = context)
                    results.append(updated_result)
                    filtered_result = self.filter_and_get_highest_confidence(self.keys, updated_result)
                else: 
                    raise Exception("Exception Occured")
            
            
        # TODO filter results, find highest conf value for each keys
        # except Exception as e:
        #     print(f"Exception: {e} has")
        #     filtered_result = []
        #     for key in self.keys:
        #         result = {'question': key,
        #                     'value': '',
        #                     'bounding_box': {'top': 0, 'left': 0, 'width': 0, 'height': 0},
        #                     'confidence_score': -1, 'page_number': -1,
        #                     'html': None
        #                 }
        #         filtered_result.append(result)
        return filtered_result, htmls
            
    def filter_and_get_highest_confidence(self, questions, results):
        filtered_results = []
        for ques in questions:
            filtered_data = [entry for page in results for entry in page if entry['question'] == ques]
            if filtered_data:
                highest_confidence_entry = max(filtered_data, key=lambda x: x['confidence_score'])
                filtered_results.append(highest_confidence_entry)
            else:
                entry = {'question': ques, 'value': None, 'score': None, 'page_number': None, 'bounding_box': None}
                filtered_results.append(entry)
        return filtered_results
    
    def get_aligned(self, encoded_image, process_image = True):
        # TODO optimize this logic: low priority
        decoded = base64.b64decode(encoded_image)
        img = np.array(Image.open(io.BytesIO(decoded)).convert("RGB"))
        corrected_image = correct_orientation(self.orientation_model, self.device, img)
        aligned_image = alignment_model_inference(self.alignment_model, self.device,
                                                  [corrected_image], process_image=process_image)
        image_pil = Image.fromarray(aligned_image[0])        
        image_bytes = io.BytesIO()
        image_pil.save(image_bytes, format='png')
        return base64.b64encode(image_bytes.getvalue())
        # return image_pil
        
if __name__ == '__main__':
    # pdf_path = '/mnt/gime-extract/global_ime/data/globalime_filtered_aligned_images/Annapurna Sugar Audited Report-2077-078_5.jpg'
    # pdf_path = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/send1.pdf"
    # pdf_path = "/home/ubuntu/info_extraction_engine_ml_demo/applesearchads.pdf"
    # pdf_path = '/home/fm-pc-lt-173/Downloads/zoom-invoice.pdf'
    # pdf_path = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/dataset/sagarmatha.jpg"
    # pdf_path = "/mnt/gime-extract/global_ime/data/globalime_filtered_aligned_images/Friends Trade Link_8.jpg" 
    # pdf_path = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/apple.pdf" 
    # pdf_path = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/meta.pdf"
    # pdf_path = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/amazon_1.pdf"
    # pdf_path = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/send1.pdf" 
    
    # pdf_paths = ["/mnt/gime-extract/global_ime/extraction_engine_demo_ml/apple.pdf","/mnt/gime-extract/global_ime/extraction_engine_demo_ml/meta.pdf","/mnt/gime-extract/global_ime/extraction_engine_demo_ml/amazon_1.pdf", "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/send1.pdf"   ]
    # BASE_IMG_PATH ="/mnt/gime-extract/global_ime/exp_data/feb5data"
    print("START")
    # BASE_IMG_PATH = "/mnt/gime-extract/global_ime/data/COR" 
    # import glob 
    
    # IPF_BASE_IMG_PATH = "/mnt/gime-extract/global_ime/data/IPF" 
    # IPF_IMAGES = os.listdir(IPF_BASE_IMG_PATH) 
    # IPF_IMAGES_DIRS = [os.path.join(IPF_BASE_IMG_PATH, img) for img in IPF_IMAGES if img.endswith(".pdf") ]

    # IMAGES_DIRS = IPF_IMAGES_DIRS
    # # IMAGES_DIRS = glob.glob(BASE_IMG_PATH + "/*.pdf*")
    # # IMAGES_DIRS = ["/mnt/gime-extract/global_ime/data/COR/MAW Investment Balance Sheet 78-79.pdf",]
    # # IMAGES_DIRS = ['/mnt/gime-extract/global_ime/data/IPF/images/Maruti Audit Report 2078_2.jpg',]
    # # IMAGES_DIRS = ["/mnt/gime-extract/global_ime/data/globalime_filtered_aligned_images/Annapurna Sugar Audited Report-2077-078_2.jpg",]
    # # # print(IMAGES)
    # # IMAGES_DIRS = [os.path.join(BASE_IMG_PATH, img) for img in IMAGES if '.pdf' in img] 
    # # IMAGES_DIRS = IMAGES_DIRS[0:4]
    # # IMAGES_DIRS = ["/mnt/gime-extract/global_ime/data/samples/1685419715_FY 77-78 Fonepay Audited Financials_Public.pdf"]
    
    # IMAGES_DIRS = ["/mnt/gime-extract/global_ime/data/architecture_docs_client/cropped/Architectural_Drawings_highlighted_5_material_symbol.jpg"]
    
    BASE_DIR = "/mnt/gime-extract/global_ime/data/architecture_docs_client/cropped"
    IMAGES = os.listdir(BASE_DIR)
    IMAGES = [img_name for img_name in IMAGES if img_name.endswith(".jpg")]
    IMAGES_DIRS = [os.path.join(BASE_DIR,img ) for img in IMAGES] 
    # pdb.set_trace()
    
    
    IMAGES_DIRS = ["/mnt/gime-extract/ocr/data/forms/amazonbusiness_sample2.pdf", ]
    
    # IMAGES_DIRS = ["/mnt/gime-extract/global_ime/data/SME/Confident International Manpower.pdf", "/mnt/gime-extract/global_ime/data/SME/R S Pharmaceuticals.pdf", 
    #                "/mnt/gime-extract/global_ime/data/SME/Friends Trade Link.pdf","/mnt/gime-extract/global_ime/data/IPF/Hotel Landmark.PDF", "/mnt/gime-extract/global_ime/data/IPF/Liberty Auditors Reports 078-79.pdf" ]
    # IMAGES_DIRS = ["/mnt/gime-extract/global_ime/data/COR/Bhatbhateni Annul Financial Statement F,Y2078-79.pdf"]
    questions = ["property, plant and equipment",
        "total assets",
        "reserves",
        "share capital",
        "non-current liabilities loans and borrowings",
        "current liabilities loans and borrowings",
        "provisions",
        "total equity and liabilities"
    ]
    
    infer = MainInference()
    
    start_time = time.time()
    
    for image_path in IMAGES_DIRS: 
        # print(image_path)
        data = infer.inference(image_path, questions, debug= True)
    print("Time Taken :", time.time()-start_time)
    
    """ For getting the iamge from the directory"""
    # # BASE_IMG_PATH = "/mnt/gime-extract/global_ime/data/globalime_filtered_aligned_images"
    # BASE_IMG_PATH = "/mnt/gime-extract/doclaynet/data/test"
    # BASE_IMG_PATH = "/mnt/gime-extract/global_ime/data/MCO"


    

    
    # for image_path in IMAGES_DIRS: 
    #     data = infer.inference(image_path, questions)
    # for image_path  in IMAGES_DIRS: 
    #     if image_path.lower().split(".")[-1] == 'pdf':
    #         print(image_path)
    #         data = infer.inference(image_path, questions)
    
    
    
    # print(data)   
    
    # #############################################################################################################
    
    # BASE_DIR = os.path.dirname(os.path.abspath(__file__))
    # # DATA_DIR = os.path.join(BASE_DIR,"test_data")
    # DATA_DIR = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/dataset"
    # DATA_DIR = "/mnt/gime-extract/ocr/data/forms"
    # infer = MainInference()
    # for pdf_name in os.listdir(DATA_DIR):
    #     print(pdf_name)
    #     if not pdf_name.endswith((".jpg", ".pdf")):
    #         continue
    #     pdf_path = os.path.join(DATA_DIR, pdf_name)
    #     questions = ['invoice number', 'Document nuber', 'Customer Name', 'locations', ""]
        
    #     data = infer.inference(pdf_path, questions)
        # print(data)
        # break
        
    # pdf_path = "/mnt/gime-extract/global_ime/extraction_engine_demo_ml/dataset/Invoice-654D29AE-0019 (1).pdf"
    # questions = ['invoice number', 'Document nuber', 'Customer Name', 'locations', ""]
    # print(infer.inference(pdf_path, questions))
    
    

    
